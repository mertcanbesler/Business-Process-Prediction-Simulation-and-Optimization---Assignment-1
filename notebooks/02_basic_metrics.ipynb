{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301ca9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TUM Master\\Business Process Prediction, Simulation and Optimization\\Assignment 1\\.venv\\lib\\site-packages\\pm4py\\util\\dt_parsing\\parser.py:82: UserWarning: ISO8601 strings are not fully supported with strpfromiso for Python versions below 3.11\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51111244c104d17a68c5ccde653c8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/31509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Event log loaded successfully with 1202267 events and 31509 cases.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ðŸ“‚ Load Event Log (Setup)\n",
    "# ============================================================\n",
    "\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define path to the .xes file (adjust if needed)\n",
    "xes_path = Path(\"../data/raw/BPI_Challenge_2017.xes\")\n",
    "\n",
    "# Load XES log using PM4Py\n",
    "log = xes_importer.apply(str(xes_path))\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "\n",
    "# Confirm successful load\n",
    "print(f\"âœ… Event log loaded successfully with {len(df)} events and {df['case:concept:name'].nunique()} cases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d3cd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 31509\n",
      "Number of events: 1202267\n",
      "Number of process variants: 15930\n",
      "Number of event labels: 26\n",
      "Number of Case Labels: 4\n",
      "Mean case length: 38.16 events\n",
      "Standard deviation of case length: 16.72 events\n",
      "Mean case duration: 21 days, 21 hours, 35 minutes, 25 seconds\n",
      "Standard deviation of case duration: 13 days, 4 hours, 3 minutes, 41 seconds\n",
      "Mean inter-event time: 14 hours, 8 minutes, 43 seconds\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ðŸ“Š Basic Event Log Analysis (Metrics)\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings for cleaner output\n",
    "import pandas as pd\n",
    "\n",
    "# Number of cases\n",
    "num_cases = df['case:concept:name'].nunique()\n",
    "print(f\"Number of cases: {num_cases}\")\n",
    "\n",
    "# Number of events\n",
    "num_events = len(df)\n",
    "print(f\"Number of events: {num_events}\")\n",
    "\n",
    "# Number of process variants\n",
    "num_variants = df.groupby('case:concept:name').apply(lambda x: ' -> '.join(x['concept:name'])).nunique()\n",
    "print(f\"Number of process variants: {num_variants}\")\n",
    "\n",
    "# Number of unique event labels (activities)\n",
    "num_event_labels = df['concept:name'].nunique()\n",
    "print(f\"Number of event labels: {num_event_labels:,}\")\n",
    "\n",
    "# case labels\n",
    "case_labels = [col for col in df.columns if col.startswith(\"case:\")]\n",
    "\n",
    "\n",
    "print(\"Number of Case Labels:\", len(case_labels))\n",
    "\n",
    "\n",
    "# Mean and standard deviation of case length\n",
    "case_lengths = df.groupby('case:concept:name').size()\n",
    "mean_case_length = case_lengths.mean()\n",
    "std_case_length = case_lengths.std()\n",
    "print(f\"Mean case length: {mean_case_length:.2f} events\")\n",
    "print(f\"Standard deviation of case length: {std_case_length:.2f} events\")\n",
    "\n",
    "# Mean and standard deviation of case duration (in days)\n",
    "case_durations = df.groupby('case:concept:name').apply(\n",
    "    lambda x: (x['time:timestamp'].max() - x['time:timestamp'].min()).total_seconds()\n",
    ")\n",
    "\n",
    "mean_case_duration = case_durations.mean()\n",
    "std_case_duration = case_durations.std()\n",
    "\n",
    "# Mean case duration â†’ convert to d/h/m/s\n",
    "mean_days = int(mean_case_duration // 86400)\n",
    "mean_hours = int((mean_case_duration % 86400) // 3600)\n",
    "mean_minutes = int((mean_case_duration % 3600) // 60)\n",
    "mean_seconds = int(mean_case_duration % 60)\n",
    "\n",
    "print(f\"Mean case duration: {mean_days} days, {mean_hours} hours, {mean_minutes} minutes, {mean_seconds} seconds\")\n",
    "\n",
    "# Std case duration â†’ convert to d/h/m/s\n",
    "std_days = int(std_case_duration // 86400)\n",
    "std_hours = int((std_case_duration % 86400) // 3600)\n",
    "std_minutes = int((std_case_duration % 3600) // 60)\n",
    "std_seconds = int(std_case_duration % 60)\n",
    "\n",
    "print(f\"Standard deviation of case duration: {std_days} days, {std_hours} hours, {std_minutes} minutes, {std_seconds} seconds\")\n",
    "\n",
    "\n",
    "# Mean Inter-Event Time\n",
    "inter_event_times = df.groupby('case:concept:name')['time:timestamp'].diff().dropna().dt.total_seconds()\n",
    "mean_inter_event_time = inter_event_times.mean()\n",
    "hours, remainder = divmod(mean_inter_event_time, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f\"Mean inter-event time: {int(hours)} hours, {int(minutes)} minutes, {int(seconds)} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff8ad591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rework rate: 0.1466 (14.66%)\n"
     ]
    }
   ],
   "source": [
    "#Rework rate calculation\n",
    "CASE, ACT, TS, LIFE = \"case:concept:name\", \"concept:name\", \"time:timestamp\", \"lifecycle:transition\"\n",
    "\n",
    "dfc = df[df[LIFE].astype(str).str.lower().eq(\"complete\")].copy()\n",
    "dfc[TS] = pd.to_datetime(dfc[TS], errors=\"coerce\")\n",
    "dfc = dfc.sort_values([CASE, TS], kind=\"mergesort\").drop_duplicates([CASE, ACT, TS])\n",
    "\n",
    "counts = dfc.groupby([CASE, ACT]).size()\n",
    "rework_events = (counts[counts > 1] - 1).sum()\n",
    "rework_rate = rework_events / len(dfc)\n",
    "\n",
    "print(f\"Rework rate: {rework_rate:.4f} ({rework_rate:.2%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median throughput time: 19 days, 2 hours, 6 minutes, 20 seconds\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamps to datetime (safety check)\n",
    "df[\"time:timestamp\"] = pd.to_datetime(df[\"time:timestamp\"], errors=\"coerce\")\n",
    "\n",
    "# Calculate case durations in seconds\n",
    "case_durations = df.groupby(\"case:concept:name\")[\"time:timestamp\"].apply(lambda x: (x.max() - x.min()).total_seconds())\n",
    "\n",
    "# Convert seconds to days for interpretability\n",
    "case_durations_days = case_durations / (24 * 3600)\n",
    "\n",
    "# Compute median and mean throughput times\n",
    "median_throughput_time = case_durations_days.median()\n",
    "mean_throughput_time = case_durations_days.mean()\n",
    "\n",
    "# Convert median throughput time (in days) to d/h/m/s\n",
    "median_seconds_total = median_throughput_time * 24 * 3600\n",
    "m_days = int(median_seconds_total // 86400)\n",
    "m_hours = int((median_seconds_total % 86400) // 3600)\n",
    "m_minutes = int((median_seconds_total % 3600) // 60)\n",
    "m_seconds = int(median_seconds_total % 60)\n",
    "\n",
    "print(f\"Median throughput time: {m_days} days, {m_hours} hours, {m_minutes} minutes, {m_seconds} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "951a401e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum throughput time: 0 days, 0 hours, 3 minutes, 21 seconds\n",
      "Maximum throughput time: 286 days, 1 hours, 44 minutes, 18 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate duration per case (in seconds)\n",
    "case_durations_seconds = df.groupby(\"case:concept:name\")[\"time:timestamp\"].apply(lambda x: (x.max() - x.min()).total_seconds())\n",
    "\n",
    "# Convert to days\n",
    "case_durations_days = case_durations_seconds / (24 * 3600)\n",
    "\n",
    "# Extract min / max\n",
    "min_throughput_days = case_durations_days.min()\n",
    "max_throughput_days = case_durations_days.max()\n",
    "\n",
    "# ---- Convert min duration ----\n",
    "min_seconds_total = min_throughput_days * 24 * 3600\n",
    "min_days = int(min_seconds_total // 86400)\n",
    "min_hours = int((min_seconds_total % 86400) // 3600)\n",
    "min_minutes = int((min_seconds_total % 3600) // 60)\n",
    "min_seconds = int(min_seconds_total % 60)\n",
    "\n",
    "# ---- Convert max duration ----\n",
    "max_seconds_total = max_throughput_days * 24 * 3600\n",
    "max_days = int(max_seconds_total // 86400)\n",
    "max_hours = int((max_seconds_total % 86400) // 3600)\n",
    "max_minutes = int((max_seconds_total % 3600) // 60)\n",
    "max_seconds = int(max_seconds_total % 60)\n",
    "\n",
    "print(f\"Minimum throughput time: {min_days} days, {min_hours} hours, {min_minutes} minutes, {min_seconds} seconds\")\n",
    "print(f\"Maximum throughput time: {max_days} days, {max_hours} hours, {max_minutes} minutes, {max_seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7260ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct event labels: 26\n"
     ]
    }
   ],
   "source": [
    "num_event_labels = df['concept:name'].nunique()\n",
    "\n",
    "print(f\"Number of distinct event labels: {num_event_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8edda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of case labels: 4\n"
     ]
    }
   ],
   "source": [
    "case_labels = [col for col in df.columns \n",
    "               if col.startswith(\"case:\") or df.groupby('case:concept:name')[col].nunique().max() == 1]\n",
    "\n",
    "num_case_labels = len(case_labels)\n",
    "print(f\"Number of case labels: {num_case_labels}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
